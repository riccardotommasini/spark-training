---
# ----------------------------------------------------------------------------------------
# -- Docs: https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker --
# ----------------------------------------------------------------------------------------
version: "3.6"
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
services:
  zookeeper:
    hostname: zookeeper
    container_name: zookeeper
    image: "${REPOSITORY}/cp-zookeeper:${CONFLUENT_DOCKER_TAG}"
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka1:
    image: "${REPOSITORY}/cp-enterprise-kafka:${CONFLUENT_DOCKER_TAG}"
    restart: always
    hostname: kafka
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka1:9092"
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  
  kafka2:
    image: "${REPOSITORY}/cp-enterprise-kafka:${CONFLUENT_DOCKER_TAG}"
    restart: always
    hostname: kafka
    container_name: kafka2
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka2:9093"
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

  schema-registry:
    hostname: schema-registry
    container_name: schema-registry
    image: "${REPOSITORY}/cp-schema-registry:${CONFLUENT_DOCKER_TAG}"
    restart: always
    ports:
      - 8084:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka1:9092
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
  
  tools:
    image: cnfltraining/training-tools:6.0
    restart: always
    hostname: tools
    container_name: tools
    volumes:
      - .:/root/confluent-streams/labs/using-ksql
    working_dir: /root/confluent-streams/labs/using-ksql
    command: /bin/bash
    tty: true


  ksqldb-server:
    container_name: ksqldb-server
    image: ${REPOSITORY}/ksqldb-server
    ports: 
      - 8088:8088
      - 8083:8083
    depends_on:
      - kafka1
      - kafka2
      - schema-registry
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka1:9092
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_AUTO_OFFSET_RESET: "earliest"
      KSQL_COMMIT_INTERVAL_MS: 2000
      KSQL_KSQL_HIDDEN_TOPICS: '^_.*'        
    # If you want to use the Confluent Hub installer to d/l component, but make them available
    # when running this offline, spin up the stack once and then run : 
    #   docker cp ksqldb:/usr/share/confluent-hub-components ./data/connect-jars
    volumes:
      - $PWD/data:/data
      - $PWD/scripts:/scripts
      - $PWD/extensions:/extensions
      - $PWD/extensions:/usr/ext

  ksqldb-cli:
    container_name: ksqldb-cli
    image: ${REPOSITORY}/cp-ksqldb-cli:${CONFLUENT_DOCKER_TAG}
    depends_on:
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
    volumes:
      - $PWD/scripts:/scripts

  jupyterlab:
    image: jupyterlab:3.0.0-spark-3.0.0
    container_name: jupyterlab
    ports:
      - 8888:8888
      - 4040:4040
    volumes:
      - shared-workspace:/opt/workspace
      - ./:/opt/workspace
  spark-master:
    image: spark-master:3.0.0
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
  spark-worker-1:
    image: spark-worker:3.0.0
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
  spark-worker-2:
    image: spark-worker:3.0.0
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
    ports:
      - 8082:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
...